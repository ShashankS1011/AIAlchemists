{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK9oGv988fCq",
        "outputId": "48c8c62d-66c4-4160-8ce4-a60d02755c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn-intelex\n",
            "  Downloading scikit_learn_intelex-2024.7.0-py310-none-manylinux1_x86_64.whl.metadata (12 kB)\n",
            "Collecting daal4py==2024.7.0 (from scikit-learn-intelex)\n",
            "  Downloading daal4py-2024.7.0-py310-none-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-intelex) (1.5.2)\n",
            "Collecting daal==2024.7.0 (from daal4py==2024.7.0->scikit-learn-intelex)\n",
            "  Downloading daal-2024.7.0-py2.py3-none-manylinux1_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from daal4py==2024.7.0->scikit-learn-intelex) (1.26.4)\n",
            "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.10/dist-packages (from daal==2024.7.0->daal4py==2024.7.0->scikit-learn-intelex) (2021.13.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (3.5.0)\n",
            "Downloading scikit_learn_intelex-2024.7.0-py310-none-manylinux1_x86_64.whl (191 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading daal4py-2024.7.0-py310-none-manylinux1_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading daal-2024.7.0-py2.py3-none-manylinux1_x86_64.whl (66.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: daal, daal4py, scikit-learn-intelex\n",
            "Successfully installed daal-2024.7.0 daal4py-2024.7.0 scikit-learn-intelex-2024.7.0\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.43.0)\n",
            "Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.26.4)\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.0 ffmpy-0.4.0 gradio-4.44.1 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.12 ruff-0.6.9 semantic-version-2.10.0 starlette-0.38.6 tomlkit-0.12.0 uvicorn-0.31.0 websockets-12.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn-intelex\n",
        "!pip install numba\n",
        "!pip install gradio\n",
        "from sklearnex import patch_sklearn, config_context\n",
        "patch_sklearn()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Intel oneAPI Shortest Path Algorithm"
      ],
      "metadata": {
        "id": "D7rDF71h8rQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import numba\n",
        "import numpy as np\n",
        "from sklearnex import patch_sklearn\n",
        "\n",
        "# Patch scikit-learn to optimize with Intel's extension\n",
        "patch_sklearn()\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'indian-cities-dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Create a graph as a dictionary (not using numba here)\n",
        "def create_graph(data):\n",
        "    graph = {}\n",
        "    for index, row in data.iterrows():\n",
        "        if row['Origin'] not in graph:\n",
        "            graph[row['Origin']] = []\n",
        "        graph[row['Origin']].append((row['Destination'], row['Distance']))\n",
        "\n",
        "        if row['Destination'] not in graph:\n",
        "            graph[row['Destination']] = []\n",
        "        graph[row['Destination']].append((row['Origin'], row['Distance']))\n",
        "    return graph\n",
        "\n",
        "# Function to convert the graph to a NumPy-friendly format for distance calculation\n",
        "def convert_graph_to_matrix(graph, cities):\n",
        "    n = len(cities)\n",
        "    city_index = {city: idx for idx, city in enumerate(cities)}  # Map city names to indices\n",
        "    distance_matrix = np.full((n, n), np.inf)  # Initialize with infinity for non-edges\n",
        "\n",
        "    for city, neighbors in graph.items():\n",
        "        if city in cities:  # Ensure city is in the list of cities we care about\n",
        "            for neighbor, distance in neighbors:\n",
        "                if neighbor in cities:  # Only consider neighbors that are in the list\n",
        "                    i, j = city_index[city], city_index[neighbor]\n",
        "                    distance_matrix[i][j] = distance\n",
        "\n",
        "    return distance_matrix, city_index\n",
        "\n",
        "# Optimized function to get the distance of a path using numba\n",
        "@numba.njit\n",
        "def get_path_distance(distance_matrix, path_indices):\n",
        "    total_distance = 0\n",
        "    for i in range(len(path_indices) - 1):\n",
        "        distance = distance_matrix[path_indices[i], path_indices[i + 1]]\n",
        "        if distance == np.inf:\n",
        "            return np.inf  # Return inf if the path is not valid\n",
        "        total_distance += distance\n",
        "    return total_distance\n",
        "\n",
        "# Finding all possible paths and the optimal one\n",
        "def find_optimal_path(start_city, cities_to_cover):\n",
        "    graph = create_graph(data)\n",
        "    all_cities = [start_city] + cities_to_cover\n",
        "\n",
        "    # Convert graph to distance matrix\n",
        "    distance_matrix, city_index = convert_graph_to_matrix(graph, all_cities)\n",
        "\n",
        "    # Generate all permutations of the cities to cover\n",
        "    all_possible_paths = []\n",
        "    for perm in itertools.permutations(cities_to_cover):\n",
        "        path = [start_city] + list(perm)\n",
        "        all_possible_paths.append(path)\n",
        "\n",
        "    # Calculate distances for each path\n",
        "    all_paths_distances = np.empty(len(all_possible_paths))\n",
        "\n",
        "    for idx, path in enumerate(all_possible_paths):\n",
        "        # Convert path to indices for distance matrix\n",
        "        path_indices = np.array([city_index[city] for city in path])\n",
        "        all_paths_distances[idx] = get_path_distance(distance_matrix, path_indices)\n",
        "\n",
        "    # Find the optimal path if there are valid paths\n",
        "    if np.isfinite(all_paths_distances).any():  # If there's at least one valid path\n",
        "        optimal_idx = np.argmin(all_paths_distances)\n",
        "        optimal_path = all_possible_paths[optimal_idx]\n",
        "        optimal_distance = all_paths_distances[optimal_idx]\n",
        "    else:\n",
        "        optimal_path = None\n",
        "        optimal_distance = np.inf\n",
        "\n",
        "    return optimal_path, optimal_distance, all_possible_paths, all_paths_distances\n",
        "\n",
        "# Example usage\n",
        "start_city = \"Agra\"\n",
        "cities_to_cover = [\"Delhi\", \"Lucknow\", \"Kanpur\"]\n",
        "print(\"Origin:\", start_city)\n",
        "print(\"Cities to cover:\", cities_to_cover)\n",
        "optimal_path, optimal_distance, all_possible_paths, path_distances = find_optimal_path(start_city, cities_to_cover)\n",
        "print(\"Optimal Path: \", optimal_path)\n",
        "print(\"Optimal Distance: \", optimal_distance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV18iSJ88n8q",
        "outputId": "653eaaac-bbd3-4d60-bc9d-3dc9b6db6cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Origin: Agra\n",
            "Cities to cover: ['Delhi', 'Lucknow', 'Kanpur']\n",
            "Optimal Path:  ['Agra', 'Delhi', 'Lucknow', 'Kanpur']\n",
            "Optimal Distance:  885.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import numba\n",
        "import numpy as np\n",
        "from sklearnex import patch_sklearn\n",
        "import gradio as gr\n",
        "\n",
        "# Patch scikit-learn to optimize with Intel's extension\n",
        "patch_sklearn()\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'indian-cities-dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Create a graph as a dictionary (not using numba here)\n",
        "def create_graph(data):\n",
        "    graph = {}\n",
        "    for index, row in data.iterrows():\n",
        "        if row['Origin'] not in graph:\n",
        "            graph[row['Origin']] = []\n",
        "        graph[row['Origin']].append((row['Destination'], row['Distance']))\n",
        "\n",
        "        if row['Destination'] not in graph:\n",
        "            graph[row['Destination']] = []\n",
        "        graph[row['Destination']].append((row['Origin'], row['Distance']))\n",
        "    return graph\n",
        "\n",
        "# Function to convert the graph to a NumPy-friendly format for distance calculation\n",
        "def convert_graph_to_matrix(graph, cities):\n",
        "    n = len(cities)\n",
        "    city_index = {city: idx for idx, city in enumerate(cities)}  # Map city names to indices\n",
        "    distance_matrix = np.full((n, n), np.inf)  # Initialize with infinity for non-edges\n",
        "\n",
        "    for city, neighbors in graph.items():\n",
        "        if city in cities:  # Ensure city is in the list of cities we care about\n",
        "            for neighbor, distance in neighbors:\n",
        "                if neighbor in cities:  # Only consider neighbors that are in the list\n",
        "                    i, j = city_index[city], city_index[neighbor]\n",
        "                    distance_matrix[i][j] = distance\n",
        "\n",
        "    return distance_matrix, city_index\n",
        "\n",
        "# Optimized function to get the distance of a path using numba\n",
        "@numba.njit\n",
        "def get_path_distance(distance_matrix, path_indices):\n",
        "    total_distance = 0\n",
        "    for i in range(len(path_indices) - 1):\n",
        "        distance = distance_matrix[path_indices[i], path_indices[i + 1]]\n",
        "        if distance == np.inf:\n",
        "            return np.inf  # Return inf if the path is not valid\n",
        "        total_distance += distance\n",
        "    return total_distance\n",
        "\n",
        "# Finding all possible paths and the optimal one\n",
        "def find_optimal_path(start_city, cities_to_cover):\n",
        "    graph = create_graph(data)\n",
        "    all_cities = [start_city] + cities_to_cover\n",
        "\n",
        "    # Convert graph to distance matrix\n",
        "    distance_matrix, city_index = convert_graph_to_matrix(graph, all_cities)\n",
        "\n",
        "    # Generate all permutations of the cities to cover\n",
        "    all_possible_paths = []\n",
        "    for perm in itertools.permutations(cities_to_cover):\n",
        "        path = [start_city] + list(perm)\n",
        "        all_possible_paths.append(path)\n",
        "\n",
        "    # Calculate distances for each path\n",
        "    all_paths_distances = np.empty(len(all_possible_paths))\n",
        "\n",
        "    for idx, path in enumerate(all_possible_paths):\n",
        "        # Convert path to indices for distance matrix\n",
        "        path_indices = np.array([city_index[city] for city in path])\n",
        "        all_paths_distances[idx] = get_path_distance(distance_matrix, path_indices)\n",
        "\n",
        "    # Find the optimal path if there are valid paths\n",
        "    if np.isfinite(all_paths_distances).any():  # If there's at least one valid path\n",
        "        optimal_idx = np.argmin(all_paths_distances)\n",
        "        optimal_path = all_possible_paths[optimal_idx]\n",
        "        optimal_distance = all_paths_distances[optimal_idx]\n",
        "    else:\n",
        "        optimal_path = None\n",
        "        optimal_distance = np.inf\n",
        "\n",
        "    return optimal_path, optimal_distance\n",
        "\n",
        "# Gradio function to process the input and display the result\n",
        "def optimize_route(start_city, cities_to_cover):\n",
        "    cities_to_cover = [city.strip() for city in cities_to_cover.split(',')]  # Parse input\n",
        "    optimal_path, optimal_distance = find_optimal_path(start_city, cities_to_cover)\n",
        "    if optimal_path is None:\n",
        "        return \"No valid path found.\", \"N/A\"\n",
        "    else:\n",
        "        return f\" -> \".join(optimal_path), f\"{optimal_distance} km\"\n",
        "\n",
        "# Create Gradio interface using updated components\n",
        "interface = gr.Interface(\n",
        "    fn=optimize_route,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Start City\"),\n",
        "        gr.Textbox(label=\"Cities to Cover (comma-separated)\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Optimal Path\"),\n",
        "        gr.Textbox(label=\"Optimal Distance (km)\")\n",
        "    ],\n",
        "    title=\"Supply Chain Route Optimizer\",\n",
        "    description=\"Enter a start city and a list of cities to cover, and get the optimal path and distance.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "id": "aXdQkwd--BTN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "0fe2f40e-f52a-4fe2-a385-7f512a43fa3e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://31948761077422ca5d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://31948761077422ca5d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}